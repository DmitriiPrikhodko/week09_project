import pandas as pd
import numpy as np
import streamlit as st

import matplotlib as mpl
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go

import os
import requests
from PIL import Image, ImageDraw, ImageFilter
from io import BytesIO

from ultralytics import YOLO
#import cv2


# –ù–∞–∑–≤–∞–Ω–∏–µ
st.title("–î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü –Ω–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è—Ö")

st.sidebar.markdown("### –ü–µ—Ä–µ–π—Ç–∏ –∫ —Å—Ç—Ä–∞–Ω–∏—Ü–µ:")
st.sidebar.page_link("main.py", label="üè† –ì–ª–∞–≤–Ω–∞—è")
st.sidebar.page_link("pages/Faces.py", label="üë§ –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü")
st.sidebar.page_link("pages/Tumors.py", label="üß† –î–µ—Ç–µ–∫—Ü–∏—è –æ–ø—É—Ö–æ–ª–µ–π –º–æ–∑–≥–∞")
st.sidebar.page_link("pages/Forest.py", label="üå≤ –°–µ–≥–º–µ–Ω—Ç–∞—Ü–∏—è –ª–µ—Å–æ–≤")

# 0. –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
model_path = 'face_detection_model/best.pt'
if os.path.exists(model_path):
    try:
        model = YOLO(model_path)
        model_loaded = True
    except Exception as e:
        st.error(f'–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}')
        model_loaded = False
else:
    st.error(f'–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {model_path}')
    st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–±–µ–¥–∏—Ç–µ—Å—å —á—Ç–æ —Ñ–∞–π–ª best.pt —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω –≤ –ø–∞–ø–∫–µ —Å –ø—Ä–æ–µ–∫—Ç–æ–º")
    model_loaded = False

# 1. –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤
col1, col2 = st.columns(2)
uploaded_files = []

with col1:
    uploaded_files_local = st.file_uploader('–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è', type=['jpg', 'png', 'jpeg'], accept_multiple_files=True)
    if uploaded_files_local:
        uploaded_files.extend(uploaded_files_local)
with col2:
    url_input = st.text_input("–ò–ª–∏ –≤–≤–µ–¥–∏—Ç–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    if url_input:
        try:
            response = requests.get(url_input)
            img = Image.open(BytesIO(response.content))
            uploaded_files.append(img)
        except:
            st.error('–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ URL')

# 3. –ó–∞–ø—É—Å–∫ –¥–µ—Ç–µ–∫—Ü–∏–∏
DEVICE = 'cpu'
# –§—É–Ω–∫—Ü–∏—è —Ä–∞–∑–º—ã—Ç–∏—è –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π
def blur_detections(img, results): # type: ignore
    draw = ImageDraw.Draw(img)
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç —Å–ø–∏—Å–∫–∞ results (—Ç.–∫. —É –≤–∞—Å –ø–æ –æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é)
    detections = results[0].boxes.xyxy.cpu().numpy()  # –ü–æ–ª—É—á–∏—Ç—å numpy –º–∞—Å—Å–∏–≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –±–æ–∫—Å–æ–≤
    for box in detections:
        x1, y1, x2, y2 = map(int, box)
        region = img.crop((x1, y1, x2, y2))
        blurred = region.filter(ImageFilter.GaussianBlur(15))
        img.paste(blurred, (x1, y1))
    return img


import io
from streamlit.runtime.uploaded_file_manager import UploadedFile  # –∏–º–ø–æ—Ä—Ç —Ç–∏–ø–∞ —Ñ–∞–π–ª–æ–≤

if model_loaded and uploaded_files:
    if st.button('–ó–∞–ø—É—Å—Ç–∏—Ç—å –¥–µ—Ç–µ–∫—Ü–∏—é', type='primary'):
        st.header('–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏:')
        for i, img_file in enumerate(uploaded_files):
            model.to(DEVICE)
            
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ñ–∞–π–ª –ª–∏ —ç—Ç–æ –∏–∑ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –∏–ª–∏ —É–∂–µ PIL.Image
                if isinstance(img_file, UploadedFile):
                    # –ï—Å–ª–∏ UploadedFile, —á–∏—Ç–∞–µ–º –±–∞–π—Ç—ã
                    file_bytes = img_file.read()
                    img = Image.open(io.BytesIO(file_bytes)).convert('RGB')
                elif isinstance(img_file, Image.Image):
                    img = img_file.convert('RGB')
                else:
                    st.error(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: {type(img_file)}")
                    continue
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∏—è —Ñ–∞–π–ª–∞: {e}")
                continue

            results = model(img)
            img_blurred = blur_detections(img.copy(), results)
            st.image(img_blurred, caption=f"–†–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {i+1}")

# 2. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
st.header('–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏')
model_metrics = pd.read_csv('face_detection_model/results.csv')
last_epoch = model_metrics.iloc[-1]

info_col1, info_col2 = st.columns(2)

with info_col1:
    st.metric('–ß–∏—Å–ª–æ —ç–ø–æ—Ö', '5')
    st.metric('–û–±—ä–µ–º train –≤—ã–±–æ—Ä–∫–∏', '13386 —Ñ–æ—Ç–æ')
    st.metric('–û–±—ä–µ–º valid –≤—ã–±–æ—Ä–∫–∏', '3347 —Ñ–æ—Ç–æ')

with info_col2:
    st.metric('mAP50', '0.885')
    st.metric('Precision', '0.883')
    st.metric('Recall', '0.809')

fig1 = go.Figure()
fig1.add_trace(go.Bar(
    x=['Precision', 'Recall', 'mAP50', 'mAP50-95'],
    y=[last_epoch['metrics/precision(B)'], 
    last_epoch['metrics/recall(B)'], 
    last_epoch['metrics/mAP50(B)'], 
    last_epoch['metrics/mAP50-95(B)']],
    marker_color=['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']
))

fig1.update_layout(
    title='–û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏',
    yaxis=dict(range=[0, 1]),
    showlegend=False
)
st.plotly_chart(fig1)

# 3. –ó–∞–ø—É—Å–∫ –¥–µ—Ç–µ–∫—Ü–∏–∏
DEVICE = 'cpu'
# –§—É–Ω–∫—Ü–∏—è —Ä–∞–∑–º—ã—Ç–∏—è –¥–µ—Ç–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π
def blur_detections(img, results):
    draw = ImageDraw.Draw(img)
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç —Å–ø–∏—Å–∫–∞ results (—Ç.–∫. —É –≤–∞—Å –ø–æ –æ–¥–Ω–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é)
    detections = results[0].boxes.xyxy.cpu().numpy()  # –ü–æ–ª—É—á–∏—Ç—å numpy –º–∞—Å—Å–∏–≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç –±–æ–∫—Å–æ–≤
    for box in detections:
        x1, y1, x2, y2 = map(int, box)
        region = img.crop((x1, y1, x2, y2))
        blurred = region.filter(ImageFilter.GaussianBlur(15))
        img.paste(blurred, (x1, y1))
    return img


import io
from streamlit.runtime.uploaded_file_manager import UploadedFile  # –∏–º–ø–æ—Ä—Ç —Ç–∏–ø–∞ —Ñ–∞–π–ª–æ–≤

if model_loaded and uploaded_files:
    if st.button('–ó–∞–ø—É—Å—Ç–∏—Ç—å –¥–µ—Ç–µ–∫—Ü–∏—é', type='primary'):
        st.header('–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–µ—Ç–µ–∫—Ü–∏–∏:')
        for i, img_file in enumerate(uploaded_files):
            model.to(DEVICE)
            
            try:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ñ–∞–π–ª –ª–∏ —ç—Ç–æ –∏–∑ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –∏–ª–∏ —É–∂–µ PIL.Image
                if isinstance(img_file, UploadedFile):
                    # –ï—Å–ª–∏ UploadedFile, —á–∏—Ç–∞–µ–º –±–∞–π—Ç—ã
                    file_bytes = img_file.read()
                    img = Image.open(io.BytesIO(file_bytes)).convert('RGB')
                elif isinstance(img_file, Image.Image):
                    img = img_file.convert('RGB')
                else:
                    st.error(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: {type(img_file)}")
                    continue
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –æ—Ç–∫—Ä—ã—Ç–∏—è —Ñ–∞–π–ª–∞: {e}")
                continue

            results = model(img)
            img_blurred = blur_detections(img.copy(), results)
            st.image(img_blurred, caption=f"–†–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {i+1}")